{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kCV(xTrainName: str, yTrainName: str, k: int, mEpoch: int) -> int:\n",
    "    \"\"\"Takes training and test inputs and finds the optimal epoch\n",
    "\n",
    "    Args:\n",
    "        xTrainName (str): the x training input name\n",
    "        yTrainName (str): the y training input name\n",
    "        k (int): the number of folds\n",
    "        mEpoch (int): the maximum epoch value to test\n",
    "\n",
    "    Returns:\n",
    "        int: the optimal epoch\n",
    "    \"\"\"\n",
    "\n",
    "    # load the files\n",
    "    xTrain = pd.read_csv(xTrainName)\n",
    "    yTrain = pd.read_csv(yTrainName)\n",
    "\n",
    "    # set the seed\n",
    "    np.random.seed(334) \n",
    "    \n",
    "    # define default optimal epoch\n",
    "    oEpoch = 0\n",
    "\n",
    "    # define the lowest number of average mistakes\n",
    "    smallestMistakes = float('inf')\n",
    "    \n",
    "    # the size of the folds\n",
    "    pSize = int(len(xTrain)/k)\n",
    "    \n",
    "    # cross validation!\n",
    "    for epoch in range(1, mEpoch):\n",
    "        avgMistakes = 0  # initalize avgMistakes\n",
    "        for fold in range(k):\n",
    "            # break up into k-folds\n",
    "            xTrainPortion = pd.concat([xTrain[: pSize*(fold)], xTrain[pSize*(fold+1):]], ignore_index=True).to_numpy()\n",
    "            xTest = xTrain[pSize*(fold): pSize*(fold+1)].to_numpy()\n",
    "            yTrainPortion = pd.concat([yTrain[: pSize*(fold)], yTrain[pSize*(fold+1):]], ignore_index=True).to_numpy()\n",
    "            yTest = yTrain[pSize*(fold): pSize*(fold+1)].to_numpy()\n",
    "            \n",
    "            # model!\n",
    "            model = perceptron.Perceptron(epoch)\n",
    "            trainStats = model.train(xTrainPortion, yTrainPortion)\n",
    "            yHat = model.predict(xTest)\n",
    "\n",
    "            # get the number of mistakes\n",
    "            avgMistakes += perceptron.calc_mistakes(yHat, yTest)\n",
    "\n",
    "        avgMistakes /= k\n",
    "\n",
    "        if smallestMistakes > avgMistakes:\n",
    "            smallestMistakes = avgMistakes\n",
    "            oEpoch = epoch\n",
    "\n",
    "    return oEpoch  #returns the average which is the optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mEpoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal epoch for the binary dataset: 4\n"
     ]
    }
   ],
   "source": [
    "oEpochBinary = kCV(\"binaryTrain.csv\", \"yTrain.csv\", 5, mEpoch)\n",
    "print(\"Optimal epoch for the binary dataset:\", oEpochBinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal epoch for the count dataset: 14\n"
     ]
    }
   ],
   "source": [
    "oEpochCount = kCV(\"countTrain.csv\", \"yTrain.csv\", 5, mEpoch)\n",
    "print(\"Optimal epoch for the count dataset:\", oEpochCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def useOptEpoch(xTrainName: str, yTrainName: str, xTestName: str, yTestName: str, oEpoch: int) -> list():\n",
    "    \"\"\"See the number of mistakes on the full dataset using the optimal epoch value\n",
    "\n",
    "    Args:\n",
    "        xTrainName (str): the x training input name\n",
    "        yTrainName (str): the y training input name\n",
    "        xTestName (str): the x test input name\n",
    "        yTestName (str): the y test input name\n",
    "        oEpoch (int): the optimal epoch value\n",
    "    \"\"\"\n",
    "\n",
    "    xTrain = perceptron.file_to_numpy(xTrainName)\n",
    "    yTrain = perceptron.file_to_numpy(yTrainName)\n",
    "    xTest = perceptron.file_to_numpy(xTestName)\n",
    "    yTest = perceptron.file_to_numpy(yTestName)\n",
    "\n",
    "    # model!\n",
    "    model = perceptron.Perceptron(oEpoch)\n",
    "    trainStats = model.train(xTrain, yTrain)\n",
    "    yHatTrain = model.predict(xTrain)\n",
    "    yHatTest = model.predict(xTest)\n",
    "\n",
    "    # get the number of mistakes\n",
    "    trainMistakes = perceptron.calc_mistakes(yHatTrain, yTrain)\n",
    "    testMistakes = perceptron.calc_mistakes(yHatTest, yTest)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Number of training mistakes:\", trainMistakes)\n",
    "    print(\"Number of test mistakes:\", testMistakes)\n",
    "\n",
    "    # return the model for solving part c\n",
    "    return model.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the binary dataset, the results are as follows:\n",
      "Number of training mistakes: 49\n",
      "Number of test mistakes: 65\n"
     ]
    }
   ],
   "source": [
    "# print out the number of mistakes using the optimal epoch and save the weights from the model\n",
    "print(\"Using the binary dataset, the results are as follows:\")\n",
    "weightsBinary = useOptEpoch(\"binaryTrain.csv\", \"yTrain.csv\", \"binaryTest.csv\", \"yTest.csv\", oEpochBinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the count dataset, the results are as follows:\n",
      "Number of training mistakes: 126\n",
      "Number of test mistakes: 546\n"
     ]
    }
   ],
   "source": [
    "# print out the number of mistakes using the optimal epoch and save the weights from the model\n",
    "print(\"Using the count dataset, the results are as follows:\")\n",
    "weightsCount = useOptEpoch(\"countTrain.csv\", \"yTrain.csv\", \"countTest.csv\", \"yTest.csv\", oEpochCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posAndNegWeights(weights: np.array, filename: str) -> tuple:\n",
    "    \"\"\"Get the most positive and negative weighted names from a perceptron model\n",
    "\n",
    "    Args:\n",
    "        weights (np.array): the weights from the model\n",
    "        filename (str): the .csv that has all the column names you want to reference\n",
    "\n",
    "    Returns:\n",
    "        tuple: a tuple of lists that have the names which have the most positive and negative weights\n",
    "    \"\"\"\n",
    "\n",
    "    # create and fill arrays with 0's to start\n",
    "    posWeight = [0]*15\n",
    "    negWeight = [0]*15\n",
    "\n",
    "    # we remove the bias since that will throw our results off\n",
    "    weightsPos = weights[1:].copy()  \n",
    "    weightsNeg = weights[1:].copy()\n",
    "\n",
    "    # load the file to get the word names\n",
    "    xTrain = pd.read_csv(filename)\n",
    "    \n",
    "    # find the index's of the most positive weights and then convert to column name\n",
    "    for index in range(len(posWeight)):\n",
    "        posWeight[index] = np.where(weightsPos == max(weightsPos))[0][0]  # get the first index of the largest weight\n",
    "        weightsPos[posWeight[index]] = float('-inf')  # set to neg infinity to make sure we don't see it again\n",
    "        posWeight[index] = xTrain.columns[posWeight[index]]  # set the name instead of the index\n",
    "\n",
    "    # find the index's of the most negative weights\n",
    "    for index in range(len(negWeight)):\n",
    "        negWeight[index] = np.where(weightsNeg == min(weightsNeg))[0][0]  # get the first index of the largest weight\n",
    "        weightsNeg[negWeight[index]] = float('inf')  # set to infinity to make sure we don't see it again\n",
    "        negWeight[index] = xTrain.columns[negWeight[index]]  # set the name instead of the index\n",
    "\n",
    "    # return the lists of the names\n",
    "    return posWeight, negWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the binary dataset, the results are as follows:\n",
      "The words with the most positive weights: ['click', 'remov', 'pleas', 'pai', 'market', 'free', 'sight', 'your', 'hour', 'these', 'help', 'deathtospamdeathtospamdeathtospam', 'death', 'name', 'dir']\n",
      "The words with the most negative weights: ['wrote', 'dn', 'up', 'which', 'rob', 'seem', 'about', 'the', 'httpaddr', 'would', 'reserv', 'version', 'too', 'http', 'prefer']\n"
     ]
    }
   ],
   "source": [
    "# get and print the names with the most positive and negative weights\n",
    "print(\"Using the binary dataset, the results are as follows:\")\n",
    "posBinary, negBinary = posAndNegWeights(weightsBinary, \"binaryTrain.csv\")\n",
    "print(\"The words with the most positive weights:\", posBinary)\n",
    "print(\"The words with the most negative weights:\", negBinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the count dataset, the results are as follows:\n",
      "The words with the most positive weights: ['numberc', 'report', 'numberb', 'dollarnumb', 'order', 'numberdnumb', 'call', 'anumb', 'usd', 'face', 'pleas', 'your', 'year', 'remov', 'numbera']\n",
      "The words with the most negative weights: ['numberp', 'd', 'file', 'w', 'but', 'iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii', 'user', 'pjnumber', 'messag', 'if', 'date', 're', 'razor', 'cnet', 'version']\n"
     ]
    }
   ],
   "source": [
    "# get and print the names with the most positive and negative weights\n",
    "print(\"Using the count dataset, the results are as follows:\")\n",
    "posCount, negCount = posAndNegWeights(weightsCount, \"countTrain.csv\")\n",
    "print(\"The words with the most positive weights:\", posCount)\n",
    "print(\"The words with the most negative weights:\", negCount)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2f57152fefe8db9534db278ad4d8a8495304b73c7464e73261dba2e0e9aeb8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
